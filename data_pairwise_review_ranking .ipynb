{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "# Integrate tqdm with Pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "df = pd.read_csv('data/Featured_Sports_and_Outdoors.csv')\n",
    "df = df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 26993.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Assign relevance scores based on features\n",
    "def relevance_score(row):\n",
    "    return row['rating'] * 0.4 + row['sentiment_score'] * 0.3 + row['normalized_helpful_votes'] * 0.3\n",
    "\n",
    "df['relevance_score'] = df.progress_apply(relevance_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 10/10 [02:15<00:00, 13.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize CSV file\n",
    "csv_filename = 'pair_labels_10000.csv'\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['pair_index1', 'pair_index2', 'label'])\n",
    "\n",
    "# Batch processing parameters\n",
    "batch_size = 1000\n",
    "\n",
    "# Process pairs in batches\n",
    "for start in tqdm(range(0, len(df.index), batch_size), desc=\"Processing Batches\"):\n",
    "    batch_indices = df.index[start:start+batch_size]\n",
    "    \n",
    "    # Generate pairs within the batch\n",
    "    batch_pairs = list(combinations(batch_indices, 2))\n",
    "    \n",
    "    # Open CSV file in append mode\n",
    "    with open(csv_filename, 'a', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Process each pair in the batch\n",
    "        for i, j in batch_pairs:\n",
    "            if df.at[i, 'relevance_score'] > df.at[j, 'relevance_score']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 0\n",
    "            \n",
    "            # Write to CSV\n",
    "            csv_writer.writerow([i, j, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Pairs DataFrame: 100%|██████████| 9991/9991 [1:00:10<00:00,  2.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "csv_filename = 'pair_labels_10000.csv'\n",
    "pair_labels_df = pd.read_csv(csv_filename)\n",
    "\n",
    "# Prepare data for training\n",
    "def create_pairs_dataframe(df, pair_labels_df, output_file='pairs_data_10000.csv', batch_size=500):\n",
    "    num_batches = (len(pair_labels_df) // batch_size) + 1\n",
    "    \n",
    "    def process_batch(batch_idx):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(pair_labels_df))\n",
    "        batch_pair_labels = pair_labels_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        batch_pairs_data = []\n",
    "        for idx, row in batch_pair_labels.iterrows():\n",
    "            i = row['pair_index1']\n",
    "            j = row['pair_index2']\n",
    "            label = row['label']\n",
    "            \n",
    "            review_1_data = df.loc[i].to_dict()\n",
    "            review_2_data = df.loc[j].to_dict()\n",
    "            \n",
    "            batch_pairs_data.append({\n",
    "                'review_1': review_1_data,\n",
    "                'review_2': review_2_data,\n",
    "                'label': label\n",
    "            })\n",
    "        \n",
    "        # Convert batch data to DataFrame\n",
    "        batch_df = pd.DataFrame(batch_pairs_data)\n",
    "        \n",
    "        # Append batch data to the CSV file\n",
    "        if batch_idx == 0:\n",
    "            batch_df.to_csv(output_file, index=False, mode='w', header=True)\n",
    "        else:\n",
    "            batch_df.to_csv(output_file, index=False, mode='a', header=False)\n",
    "    \n",
    "    # Using ThreadPoolExecutor to parallelize batch processing\n",
    "    with ThreadPoolExecutor(max_workers=12) as executor:\n",
    "        list(tqdm(executor.map(process_batch, range(num_batches)), total=num_batches, desc=\"Creating Pairs DataFrame\"))\n",
    "\n",
    "create_pairs_dataframe(df, pair_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_df = pd.read_csv('pairs_data_10000.csv')\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_df, test_df = train_test_split(pairs_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"{'timestamp': '2021-02-10 14:02:26.894', 'rating': 5.0, 'helpful_vote': 0, 'title': 'Great stirrups with bar none grip', 'text': 'I have to say, the grip on these are pretty great. So great in fact that when my boy walked off the mounting block when I had one foot in the stirrup, I became hopelessly stuck and pulled the entire saddle askew in my attempt to free myself. So yeah. Buy these.', 'asin': 'B002HPNBMU', 'verified_purchase': True, 'user_id': 'AGGZ357AO26RQZVRLGU4D4N52DZQ', 'language': 'en', 'word_count': 58, 'avg_sentence_length': 14.5, 'sentiment_score': 0.8856, 'key_phrases': \"\"['I', 'the grip', 'these', 'fact', 'my boy', 'the mounting block', 'I', 'one foot', 'the stirrup', 'I', 'the entire saddle askew', 'my attempt', 'myself', 'these']\"\", 'review_length': 261, 'normalized_helpful_votes': 0.0, 'relevance_score': 2.26568}\",\"{'timestamp': '2021-03-04 19:30:44.430', 'rating': 5.0, 'helpful_vote': 0, 'title': 'Nice bait', 'text': 'My grandson is always losing these lures But we talked about it...He said that was a good thing because that means the fish are biting on them a lot which makes sense LOL So I got another box. He loves them too', 'asin': 'B08SPY5HM5', 'verified_purchase': False, 'user_id': 'AFFZVSTUS3U2ZD22A2NPZSKOCPGQ', 'language': 'en', 'word_count': 45, 'avg_sentence_length': 22.5, 'sentiment_score': 0.9313, 'key_phrases': \"\"['My grandson', 'these lures', 'we', 'it', 'He', 'that', 'a good thing', 'that', 'the fish', 'them', 'which', 'sense', 'I', 'another box', 'He', 'them']\"\", 'review_length': 210, 'normalized_helpful_votes': 0.0, 'relevance_score': 2.27939}\",0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('pairs_data_10000.csv', 'r', encoding='utf-8') as file:\n",
    "    for idx, line in enumerate(file):\n",
    "        if idx == 503:  \n",
    "            print(line)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 502 in pairs_data_10000.csv has been corrected.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Function to correct the CSV file by rewriting specific lines\n",
    "def correct_csv_line(csv_file, line_number, corrected_line):\n",
    "    # Read all lines from the CSV file\n",
    "    with open(csv_file, 'r', newline='', encoding='utf-8') as file:\n",
    "        lines = list(csv.reader(file))\n",
    "\n",
    "    # Replace the specific line with the corrected content\n",
    "    lines[line_number - 1] = corrected_line  # line_number - 1 because list is zero-indexed\n",
    "\n",
    "    # Write the corrected lines back to the CSV file\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(lines)\n",
    "\n",
    "# Example usage to correct line 102 in pairs_data.csv\n",
    "csv_file = 'pairs_data_10000.csv'\n",
    "line_number = 502  # Adjust this as per the actual line number in your file\n",
    "\n",
    "# Corrected line based on the provided example (adjust as needed)\n",
    "corrected_line = [\n",
    "    '{\"timestamp\": \"2021-02-10 14:02:26.894\", \"rating\": 5.0, \"helpful_vote\": 0, \"title\": \"Great stirrups with bar none grip\", \"text\": \"I have to say, the grip on these are pretty great. So great in fact that when my boy walked off the mounting block when I had one foot in the stirrup, I became hopelessly stuck and pulled the entire saddle askew in my attempt to free myself. So yeah. Buy these.\", \"asin\": \"B002HPNBMU\", \"verified_purchase\": true, \"user_id\": \"AGGZ357AO26RQZVRLGU4D4N52DZQ\", \"language\": \"en\", \"word_count\": 58, \"avg_sentence_length\": 14.5, \"sentiment_score\": 0.8856, \"key_phrases\": \"[\\'I\\', \\'the grip\\', \\'these\\', \\'fact\\', \\'my boy\\', \\'the mounting block\\', \\'I\\', \\'one foot\\', \\'the stirrup\\', \\'I\\', \\'the entire saddle askew\\', \\'my attempt\\', \\'myself\\', \\'these\\']\", \"review_length\": 261, \"normalized_helpful_votes\": 0.0, \"relevance_score\": 2.26568}',\n",
    "    '{\"timestamp\": \"2021-03-04 19:30:44.430\", \"rating\": 5.0, \"helpful_vote\": 0, \"title\": \"Nice bait\", \"text\": \"My grandson is always losing these lures But we talked about it...He said that was a good thing because that means the fish are biting on them a lot which makes sense LOL So I got another box. He loves them too\", \"asin\": \"B08SPY5HM5\", \"verified_purchase\": false, \"user_id\": \"AFFZVSTUS3U2ZD22A2NPZSKOCPGQ\", \"language\": \"en\", \"word_count\": 45, \"avg_sentence_length\": 22.5, \"sentiment_score\": 0.9313, \"key_phrases\": \"[\\'My grandson\\', \\'these lures\\', \\'we\\', \\'it\\', \\'He\\', \\'that\\', \\'a good thing\\', \\'that\\', \\'the fish\\', \\'them\\', \\'which\\', \\'sense\\', \\'I\\', \\'another box\\', \\'He\\', \\'them\\']\", \"review_length\": 210, \"normalized_helpful_votes\": 0.0, \"relevance_score\": 2.27939}',\n",
    "    \"0\"\n",
    "]\n",
    "\n",
    "# Correct the CSV line\n",
    "correct_csv_line(csv_file, line_number, corrected_line)\n",
    "\n",
    "print(f\"Line {line_number} in {csv_file} has been corrected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def create_xgb_data(df):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        features = []\n",
    "        for feature in ['rating', 'word_count', 'avg_sentence_length', 'sentiment_score', 'review_length', 'normalized_helpful_votes']:\n",
    "            try:\n",
    "                review1_features = eval(row['review_1'])  \n",
    "                review2_features = eval(row['review_2']) \n",
    "                feature_diff = review1_features.get(feature, 0) - review2_features.get(feature, 0)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing features: {e}\")\n",
    "                feature_diff = 0  \n",
    "            \n",
    "            features.append(feature_diff)\n",
    "        \n",
    "        X.append(features)\n",
    "        y.append(row['label'])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = create_xgb_data(train_df)\n",
    "X_test, y_test = create_xgb_data(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlodzimierrr/miniconda3/envs/sentiment/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:23:58] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model with GPU\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'rank:pairwise',\n",
    "    'eta': 0.1,\n",
    "    'gamma': 1.0,\n",
    "    'min_child_weight': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'eval_metric': 'ndcg'\n",
    "}\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wlodzimierrr/miniconda3/envs/sentiment/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [16:32:11] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate\n",
    "y_pred = bst.predict(dtest)\n",
    "ndcg = ndcg_score([y_test], [y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG Score: 0.9436917984256741\n"
     ]
    }
   ],
   "source": [
    "print(f'NDCG Score: {ndcg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to disk\n",
    "with open('pairwise_ranking_model.pkl', 'wb') as f:\n",
    "    pickle.dump(bst, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the given DataFrame is named `df`\n",
    "# Select relevant columns\n",
    "columns = ['text', 'sentiment_score', 'word_count', 'avg_sentence_length', 'normalized_helpful_votes', 'relevance_score']\n",
    "df_selected = df[columns]\n",
    "\n",
    "# Save to a new CSV file\n",
    "df_selected.to_csv('reviews_for_classification.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'reviews_for_classification.csv' created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
